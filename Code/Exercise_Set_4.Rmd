---
title: "Exercise Set 4"
author: "Cora Ferguson"
date: "2/18/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1
A big challenge in science today is reproducibility.  A huge emphasis is placed on recording everything performed during an experimental protocol, and this is for good reason - if others can replicate the results of an experiment, it validates the findings and keeps scientists accountable.  Where there is less emphasis on accountability is in data analysis.  Ironically, data analysis is arguably the most important part of scientific research but how data is analysed and the methodology behind it is murky.  For this reason, I chose the article titled [*Package Management for Reproducible R Code*](https://www.r-bloggers.com/2018/01/package-management-for-reproducible-r-code/){target="_blank"}.

This article outlines one of the growing challenges that the *R* community faces today - how to maintain reproducibility while adapting to new packages and ever evolving technological systems.  Just like any software, *R* is constantly evolving and outside programmers are building new packages to improve its functionality and versatility.  While this innovation has improved the development of the software, it also places a larger degree of responsibility on the user to ensure that others can use their code in the way it was intended to.  The article outlines how for some, this is as simple as creating projects with version control using programs like *GitHub*.  For more complicated projects, containers like *Docker* can be used to keep track of all of the dependencies that are required for your project.  These programs not only help you stay organized and keep track of changes, but they also allow others to reproduce your code which maintains the integrity of your work and ultimately helps the field progress. 

# Question 2
First, I will import the colleges dataset and the libraries that are necessary to run the different sorting and manipulating tasks outlined by the exercises.

```{r}
# import the necessary libraries
library(readr)
library(here)
library(dplyr)

# import the data
colleges <- read_csv(here("Data", "colleges2015.csv"))
```

12. Filter the rows for colleges in Great Lakes or New England regions.
```{r}
# filter the rows for colleges in the great lake or new England regions
colleges %>%
  filter(region == "New England" | region == "Great Lakes")
```

13. Which school in Great Lakes or New England region has the highest first-year retention rate in this reduced data set.
```{r}
# figure out which school has the highest first year retention rate
colleges %>%
  filter(region == "New England" | region == "Great Lakes") %>% 
     arrange(desc(FYretention)) %>%
     slice(1:2)
```
Sacred Heart Major Seminary school in Detroit and Yeshiva Gedolah of Greater Detroit in Oak Park are tied for the highest first year retention rate of 100%.

14. Which school in Great Lakes or New England region has the lowest admissions rate in this reduced data set.
```{r}
# figure out which school has the lowest admissions rate
colleges %>%
  filter(region == "New England" | region == "Great Lakes") %>% 
     arrange(admissionRate) %>% 
     slice(1)
```
Harvard has the lowest admission rate out of all of these colleges and/or universities. 

15. Using the full data set, create a column giving the cumulative average cost of attendance, assuming that students finish in four years and that costs increase 3% per year. Name this new column `total_cost_4yrs`.

```{r}
# define variables that outline the cost        for each year of college
year1 = colleges$cost
year2 = year1*1.03
year3 = year2*1.03
year4 = year3*1.03

# use mutate to add a column outlining the total cost of attendance
colleges <- colleges %>%
     mutate(total_cost_4yrs = year1+year2+year3+year4, na.rm = TRUE)

colleges
```

16. Using the full data set, summarize the total cost of attendance by region by calculating the 10th, 50th, and 90th percentiles. Then arrange them by median costs (from highest to lowest).
```{r}
colleges <- colleges %>%
     group_by(region) %>%
     summarise(quantile = scales::percent(c(0.1, 0.5, 0.9)),
               cost = quantile(total_cost_4yrs,c(0.1, 0.5, 0.9), na.rm = TRUE)) %>%
     arrange(desc(cost))

colleges
```

17. Place your result from the previous question in a nicely formatted, HTML friendly, table.
```{r}
# use the knitr function to clean up the output and add a caption
knitr::kable(colleges, digits = 3, caption = "Estimated cost of 4 year Universities from 2015 to 2019 organized by region.")
```

# Question 3
The first thing that I am going to do is load the data set:
```{r}
data("iris")
```

a. Now I am going to create two new variables outlining the ratios between the lengths and widths of the petals and sepals.  The last variable will state whether the petal to sepal length ratio is greater than 0.75.
```{r}
iris <- iris %>% 
  mutate(p.to.s.width = Petal.Width/Sepal.Width,
         p.to.s.length = Petal.Length/Sepal.Length,
         p.to.s.length.ratio = (p.to.s.length>.75))

iris
```

b. Now I will calculate the number of observations in the dataset, the average sepal length, the 25th percentile of the petal to sepal length, and the proportion of petal to sepal length ratios larger than 0.75.
```{r}
iris_species <-
  iris %>%
  group_by(Species) %>%
  summarise(n.observations = n(),
            Mean.Sepal.Length = mean(Sepal.Length),
            First.quartile.p.to.s.length = quantile(p.to.s.length, .25),
            p.to.s.ratio.over.75 = (n_distinct(p.to.s.length.ratio))/n.observations)

iris_species
```

c. Now, I will find the means for all of the numerical variables in the data based on the species.
```{r}
iris_species %>%
  group_by(Species) %>%
  summarise(across(where(is.numeric), mean))
```

d. Now I will subset the data so I only have the versicolor flowers with Petal to Sepal length ratios above 0.75.  
```{r}
iris %>%
  filter(Species == "versicolor", 
         p.to.s.length.ratio == TRUE) %>%
  select(p.to.s.length)
```
e. Now I will go back to the original iris data and subset it by species to keep the flowers with the two largest petal widths.
```{r}
iris %>%
  group_by(Species) %>%
  select(Petal.Width) %>%
      arrange(desc(Petal.Width)) %>%
        slice(1:2)
  
```

